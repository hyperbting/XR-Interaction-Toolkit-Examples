{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b5fc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import sys\n",
    "sys.path.extend(['..'])\n",
    "from utils import Config\n",
    "from data import LSTMCSVDataset\n",
    "import copy \n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfce3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureCSVDatasetv2(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, output_type='quaternion', look_back=10, step_value = 1):\n",
    "        files = os.listdir(root_path)\n",
    "        files = [f for f in files if f.endswith('.csv')]\n",
    "        self.stats = {\n",
    "                'up': 0,\n",
    "                'down': 0,\n",
    "                'forward': 0,\n",
    "                'backward': 0,\n",
    "                'none': 0\n",
    "        }\n",
    "        gestures = []\n",
    "        for file in files:\n",
    "            csv_data = pd.read_csv(os.path.join(root_path, file))\n",
    "            up_gestures_idx = csv_data[csv_data['gesture']=='Up0'].index.to_numpy()\n",
    "            down_gestures_idx = csv_data[csv_data['gesture']=='Down0'].index.to_numpy()\n",
    "            forward_gestures_idx = csv_data[csv_data['gesture']=='Forward0'].index.to_numpy()\n",
    "            backward_gestures_idx = csv_data[csv_data['gesture']=='Backward0'].index.to_numpy()\n",
    "            gestures_idx = np.concatenate([up_gestures_idx, down_gestures_idx, forward_gestures_idx, backward_gestures_idx])\n",
    "#             print(gestures_idx.shape)\n",
    "            \n",
    "            csv_data['relativeHandRPosx'] = csv_data['headPosx']-csv_data['handRPosx']\n",
    "            csv_data['relativeHandRPosy'] = csv_data['headPosy']-csv_data['handRPosy']\n",
    "            csv_data['relativeHandRPosz'] = csv_data['headPosz']-csv_data['handRPosz']\n",
    "            csv_data['relativeHandLPosx'] = csv_data['headPosx']-csv_data['handLPosx']\n",
    "            csv_data['relativeHandLPosy'] = csv_data['headPosy']-csv_data['handLPosy']\n",
    "            csv_data['relativeHandLPosz'] = csv_data['headPosz']-csv_data['handLPosz']\n",
    "#             csv_data['relativeTracker1Posx'] = csv_data['headPosx']-csv_data['tracker1Posx']\n",
    "#             csv_data['relativeTracker1Posy'] = csv_data['headPosy']-csv_data['tracker1Posy']\n",
    "#             csv_data['relativeTracker1Posz'] = csv_data['headPosz']-csv_data['tracker1Posz']\n",
    "            fields = set(csv_data.keys())\n",
    "            needed_feats = []\n",
    "            if output_type=='quaternion':\n",
    "                needed_feats = ['headPosy', 'headRotQx', 'headRotQy', 'headRotQz', 'headRotQw',\n",
    "                    'relativeHandRPosx', 'relativeHandRPosy', 'relativeHandRPosz', 'handRRotQx', 'handRRotQy', 'handRRotQz', 'handRRotQw',\n",
    "                    'relativeHandLPosx', 'relativeHandLPosy', 'relativeHandLPosz', 'handLRotQx', 'handLRotQy', 'handLRotQz', 'handLRotQw']\n",
    "            remove_fields = list(fields - set(needed_feats))\n",
    "            for field in remove_fields:\n",
    "                csv_data = csv_data.drop(columns=[field])\n",
    "#             print(fields)\n",
    "            data = np.array([csv_data]).squeeze(0)\n",
    "#             print(data.shape)\n",
    "            scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "            scaler.fit(data)\n",
    "            scaled_data = scaler.transform(data)\n",
    "            # lstm_data = []\n",
    "            print()\n",
    "            for i in range(len(scaled_data)-look_back-1):\n",
    "                a = scaled_data[i:(i+look_back):step_value]\n",
    "                if self.check_proximal_gesture_type(i, up_gestures_idx):\n",
    "                    gestures.append((a,1))\n",
    "                    self.stats['up']+=1\n",
    "                elif self.check_proximal_gesture_type(i, down_gestures_idx):\n",
    "                    gestures.append((a,2))\n",
    "                    self.stats['down']+=1\n",
    "                elif self.check_proximal_gesture_type(i, forward_gestures_idx):\n",
    "                    gestures.append((a,3))\n",
    "                    self.stats['forward']+=1\n",
    "                elif self.check_proximal_gesture_type(i, backward_gestures_idx):\n",
    "                    gestures.append((a,4))\n",
    "                    self.stats['backward']+=1\n",
    "                else:\n",
    "                    gestures.append((a,0))\n",
    "                    self.stats['none']+=1\n",
    "                # lstm_data.append(a)\n",
    "        self.gestures = gestures\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gestures)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.gestures[idx][0], self.gestures[idx][1]\n",
    "        \n",
    "    def check_proximal_gesture_type(self, idx, gestures_idx, thresh=10):\n",
    "        for jdx in gestures_idx:\n",
    "            if abs(idx-jdx)<thresh:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6dd48ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = GestureCSVDatasetv2(os.path.join('..',Config['dataset_path']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df50de17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61627"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a11d6201",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LSTMClassifier,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.lstm_1 = nn.LSTM(self.input_size, 100, batch_first=True)\n",
    "        self.fc1 = nn.Linear(1000, 512)\n",
    "        self.bn2 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.bn3 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.bn4 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, output_size)\n",
    "        self.h1 = self.init_hidden(batch_size=Config['batch_size'],device='cuda:0')\n",
    "\n",
    "    def init_hidden(self, batch_size, device='cpu'):\n",
    "        return (torch.zeros(1, batch_size , 100).to(device), torch.zeros(1, batch_size , 100).to(device))\n",
    "    \n",
    "    def forward(self, x, device='cpu'):\n",
    "        out, self.h1 = self.lstm_1(x, self.h1)\n",
    "#         print(out.shape)\n",
    "        out = out.reshape(out.shape[0],-1)\n",
    "        out = nn.Tanh()(self.bn2(self.fc1(out)))\n",
    "        out = nn.Tanh()(self.bn3(self.fc2(out)))\n",
    "        out = nn.Tanh()(self.bn4(self.fc3(out)))\n",
    "        out = self.fc4(out)\n",
    "#         print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa02a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(dataloader, dataset_sizes, model, criterion, optimizer, device, num_epochs=Config['num_epochs'], batch_size=Config['batch_size']):\n",
    "    print(Config)\n",
    "\n",
    "    start_time = datetime.now()\n",
    "    print(\"Start Time =\", start_time)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    best_loss = 100.0\n",
    "    best_wts = copy.deepcopy(model.state_dict())\n",
    "    dummy_input = None\n",
    "\n",
    "    if Config['tensorboard_log']:\n",
    "        writer = SummaryWriter(Config['model_path'])\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase=='train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0 \n",
    "            running_total = 0\n",
    "            print(dataloader[phase])\n",
    "            for inputs, labels in tqdm(dataloader[phase]):\n",
    "                print(inputs.shape, labels.shape)\n",
    "                # if inputs.shape[0]!=Config['batch_size']:\n",
    "                    # continue\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    print('Loaded')\n",
    "                    model.h1= model.init_hidden(batch_size=inputs.shape[0], device='cuda:0')\n",
    "\n",
    "                    if dummy_input is None:\n",
    "                        dummy_input = inputs\n",
    "                    print('Forward prop')\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "#                     print(outputs.shape, labels[:,-1,:].shape)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if Config['use_cuda']:\n",
    "                        l2_regularization = torch.tensor(0.).cuda()\n",
    "                    else:\n",
    "                        l2_regularization = torch.tensor(0.)\n",
    "                    \n",
    "                    for param in model.parameters():\n",
    "                        l2_regularization += torch.norm(param, 2)**2\n",
    "\n",
    "                    loss += 1e-5 * l2_regularization\n",
    "                    print('Backprop')\n",
    "                    if phase =='train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        model.h1[0].detach_()\n",
    "                    running_loss += loss.item()*inputs.size(0)\n",
    "                    running_corrects += (preds==labels).sum().item()\n",
    "                    running_total += inputs.size(0)\n",
    "            epoch_loss = running_loss/running_total\n",
    "            epoch_acc = running_corrects/running_total\n",
    "            print(f'Epoch {epoch} Loss: {epoch_loss:.4f} Accuracy: {epoch_acc:.4f}')\n",
    "            if epoch_loss < best_loss and phase=='valid':\n",
    "                best_wts = copy.deepcopy(model.state_dict())\n",
    "                print(outputs[-1,:], labels[-1,-1,:])\n",
    "            writer.add_scalar(phase+'_loss', epoch_loss, global_step=epoch)\n",
    "        if (epoch+1)%5==0:\n",
    "            model.h1 = model.init_hidden(batch_size=1, device='cuda:0')\n",
    "            torch.onnx.export(model,\n",
    "                      dummy_input[0].unsqueeze(0),\n",
    "                      os.path.join(\n",
    "                            Config['model_path'],\n",
    "                            f'checkpoints/model_{epoch}.onnx'\n",
    "                        ),\n",
    "                      )\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(\n",
    "                    Config['model_path'],\n",
    "                    f'checkpoints/model_{epoch}.pth'\n",
    "                )\n",
    "            )\n",
    "    print('Training ended')\n",
    "    end_time = datetime.now()\n",
    "    print(\"End Time =\", end_time)\n",
    "    print(\"Total Time =\", end_time-start_time)\n",
    "    torch.save(\n",
    "        best_wts,\n",
    "        os.path.join(\n",
    "            Config['model_path'],\n",
    "            'checkpoints/model_final.pth'\n",
    "        )\n",
    "    )\n",
    "    model.load_state_dict(best_wts)\n",
    "    torch.onnx.export(model,\n",
    "                      dummy_input,\n",
    "                      os.path.join(\n",
    "                            Config['model_path'],\n",
    "                            'checkpoints/model_final.onnx'\n",
    "                      ),\n",
    "                      export_params=True\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729bd4aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 55464, 'valid': 6163}\n",
      "{'dataset_path': 'Data_Exp/Exp1', 'model_path': 'models/lstm_classifier', 'onnx_model_path': 'exp1_lstm_model_final.onnx', 'tensorboard_log': True, 'use_cuda': True, 'lr': 0.001, 'num_epochs': 1000, 'batch_size': 256, 'num_workers': 2, 'data_type': 'relative'}\n",
      "Start Time = 2021-04-22 18:09:59.464731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                       | 0/217 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000001E259A077C0>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(Config['model_path'], exist_ok=True)\n",
    "os.makedirs(os.path.join(Config['model_path'],'logs'),exist_ok=True)\n",
    "os.makedirs(os.path.join(Config['model_path'],'checkpoints'),exist_ok=True)\n",
    "\n",
    "# dataset = LSTMCSVDataset(root_path=Config['dataset_path'])\n",
    "model = LSTMClassifier(input_size=19, output_size=5)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() and Config['use_cuda'] else 'cpu')\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) #rmsprop, adam\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "ratio = [int(len(dataset)*0.9), len(dataset)-int(len(dataset)*0.9)]\n",
    "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, ratio)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                    train_dataset,\n",
    "                    batch_size = Config['batch_size'],\n",
    "                    shuffle=True,\n",
    "                    num_workers = Config['num_workers']\n",
    "                )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "                    valid_dataset,\n",
    "                    batch_size = Config['batch_size'],\n",
    "                    shuffle=False,\n",
    "                    num_workers = Config['num_workers']\n",
    "                )\n",
    "dataloaders = {\n",
    "    'train' : train_loader,\n",
    "    'valid' : valid_loader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train' : len(train_dataset),\n",
    "    'valid' : len(valid_dataset)\n",
    "}\n",
    "print(dataset_sizes)\n",
    "train(\n",
    "    dataloaders, \n",
    "    dataset_sizes,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08365589",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efb256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
